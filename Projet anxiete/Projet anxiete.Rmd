---
title: "Projet anxiete"
author: "Matis Larouche"
date: "2024-05-28"
output: html_document
---
###Introduction
Depuis la Covid-19 la sensibilité quant au trouble mentale à augmenter drastiquement. Beaucoup de gens ont souffert d'anxiété et de stress suite à tous ces évènements. Je me suis donc questionné sur les causes de ces problèmes d'où j'ai découvert une passion pour la psychologie. J'ai voulu joindre le volait informatique avec la psychologie pour mon cours individualisé. J'ai donc choisi des données sur l'anxiété en lien avec les jeux vidéos pour réaliser ce projet.

### La source des données
J'ai pris mes données sur Kaggle où j'ai aussi eu accès au formulaire que les répondants ont eu à répondre pour fournir leur données.

il y a un total de 55 variables pour 14 300 entrées ce qui sera assez pour faire tous les tests imaginables.

Voici le lien de la source de données: https://www.kaggle.com/datasets/divyansh22/online-gaming-anxiety-data/data

```{r load-packages, message = FALSE, warning = FALSE}
library(tidyverse)
library(broom)
library(skimr)
library(dplyr)
library(FactoMineR)
library(factoextra)
library(ggplot2)
library(tidyr)
library(stringr)
```

```{r load_data}
data <- read.csv("Data/GamingStudy_data.csv",sep=",")
```

```{r glimpse_data}

glimpse(data)

```

## Objectifs

Dans ce projet, il y a trois objectifs. Tout d'abord, il y a l'objectif d'explorer les données afin d'analyser les données potentielles pouvant permettre d'établir une relation entre celle-ci et l'anxiété des répondant du sondage. Par la suite, je vais créer une analyse de composantes principales (ACP) afin de vérifier si mes données ont un quelconque lien pour prédire l'anxiété et pour finir je vais faire une régression de la source des données pour valider ce que mon ACP a donné comme résultats.

## Nettoyage de données
```{r RemoveColumn}

# Suppression des colonnes B et D en utilisant l'indexation par noms
data_column <- data[, !(names(data) %in% c("League", "highestleague"))]

```
```{r RemoveNA}

# Suppression des lignes contenant des valeurs manquantes
data_clean <- na.omit(data_column)

# Utilisation de gsub pour remplacer <e7> par la lettre ç
data_clean$Birthplace <- gsub("<e7>", "ç", data_clean$Birthplace, fixed = TRUE)

# Assurez-vous que la colonne 'degree' existe
if("Degree" %in% colnames(data_clean)) {
  # Utilisation de gsub pour remplacer <a0> par une chaîne vide
  data_clean$Degree <- gsub("<a0>", "", data_clean$Degree)

  # Vérification des résultats
  head(data_clean$Degree)
} else {
  print("La colonne 'degree' n'existe pas dans le jeu de données.")
}

```
```{r skim_data}

skim(data_clean)

```

## Jeux GAD et SPIN

```{r GAD}
data_GAD <- data_clean %>%
  select(S..No., GAD1, GAD2, GAD3, GAD4, GAD5, GAD6, GAD7)

```

```{r SPIN}
data_SPIN <- data_clean %>%
  select(S..No., SPIN1, SPIN2, SPIN3, SPIN4, SPIN5, SPIN6, SPIN7,  SPIN8, SPIN9, SPIN10, SPIN11, SPIN12, SPIN13, SPIN14, SPIN15, SPIN16, SPIN17)

```
##ACP

```{r ACP_GAD}
res.pca <- PCA(data_GAD[, !names(data_GAD) %in% "S..No."], graph = FALSE)

# elements dans la PCA
print(res.pca)

# pour aller chercher les valeurs propres
res.pca$eig

#------ Visualisation et interpretation -----

# Valeurs propres / Variances

library("factoextra")
eig.val <- get_eigenvalue(res.pca)
eig.val

# ici on pourrait aller jusqu'a 4 axes principaux qui expliquent 80.45% de 
# la variabilite des donnees initiales

# on peux aussi visualiser
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))

# ici on est capable de selection notre nombre d'axes et donc de nouvelles
# variables reduites

# -------Graphique des variables --------

var <- get_pca_var(res.pca)
var

# var$coord: coordonnees des variables pour creer un nuage de points.
# var$cos2: cosinus carre des variables. Represente la qualite de representation 
# des variables sur le graphique de l'ACP. Il est calcule comme etant les 
# coordonnees au carre: var.cos2 = var.coord * var.coord.
# var$contrib: contient les contributions (en pourcentage), des variables, aux 
# composantes principales. La contribution d'une variable (var) e une composante 
# principale donnee: (var.cos2 * 100) / (total cos2 du composant).

# Coordonnees
head(var$coord)
# Correlation
head(var$cor)
# Cos2: qualite de representation
head(var$cos2)
# Contributions aux composantes principales
(var$contrib)


# visualisation des coordonnees:
fviz_pca_var(res.pca, col.var = "black", axes = c(1, 2))
fviz_pca_var(res.pca, col.var = "black", axes = c(2, 3))
fviz_pca_var(res.pca, col.var = "black", axes = c(1, 5))

# Visualisation qualite:
library("corrplot")
corrplot(var$cos2, is.corr=FALSE)

# Colorer en fonction du cos2: qualite de representation
fviz_pca_var(res.pca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE # evite le chevauchement de texte
)
fviz_pca_var(res.pca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, # evite le chevauchement de texte
             axes = c(1,3)
)


# visualisation de la contribution:
library("corrplot")
corrplot(var$contrib, is.corr=FALSE)    

# Contributions des variables e PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
# Contributions des variables e PC3
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)



#------  Graphique des individus ------

ind <- get_pca_ind(res.pca)
ind

# Coordonnees des individus
head(ind$coord)
# Qualite des individus
head(ind$cos2)
# Contributions des individus
head(ind$contrib)

# visualisation

#fviz_pca_ind (res.pca)
#fviz_pca_ind (res.pca, axes = c(1,3))
#fviz_pca_ind (res.pca, col.ind = "cos2",
#              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
#              repel = TRUE # evite le chevauchement de texte
#)
#fviz_pca_ind (res.pca, col.ind = "cos2",
#              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
#              repel = TRUE, # evite le chevauchement de texte
#axes = c(3,4)
#              )



# ----- BIPLOT -----

# pour visualiser les deux: variables et ind
#fviz_pca_biplot(res.pca, repel = TRUE,
#                col.var = "#2E9FDF", # Couleur des variables
#                col.ind = "#696969"  # Couleur des individues
#)
#fviz_pca_biplot(res.pca, repel = TRUE,
#                col.var = "#2E9FDF", # Couleur des variables
#                col.ind = "#696969",  # Couleur des individues
#axes = c(1,3)
#                )

# Extraire les 4 premières dimensions de l'ACP
principal_components <- res.pca$ind$coord[, 1:4]

# Ajouter ces dimensions à votre jeu de données original
data_with_pca <- cbind(data_clean, principal_components)

# Renommer les colonnes des composantes principales
colnames(data_with_pca)[(ncol(data_clean) + 1):(ncol(data_clean) + 4)] <- paste0("DimGAD", 1:4)

# Afficher les premières lignes du nouveau jeu de données pour vérifier
head(data_with_pca)

```
```{r ACP_SPIN}
res.pca <- PCA(data_SPIN[, !names(data_SPIN) %in% "S..No."], graph = FALSE, ncp=9)

# elements dans la PCA
print(res.pca)

# pour aller chercher les valeurs propres
res.pca$eig

#------ Visualisation et interpretation -----

# Valeurs propres / Variances

library("factoextra")
eig.val <- get_eigenvalue(res.pca)
eig.val

# ici on pourrait aller jusqu'a 4 axes principaux qui expliquent 80.45% de 
# la variabilite des donnees initiales

# on peux aussi visualiser
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0, 50))

# ici on est capable de selection notre nombre d'axes et donc de nouvelles
# variables reduites

# -------Graphique des variables --------

var <- get_pca_var(res.pca)
var

# var$coord: coordonnees des variables pour creer un nuage de points.
# var$cos2: cosinus carre des variables. Represente la qualite de representation 
# des variables sur le graphique de l'ACP. Il est calcule comme etant les 
# coordonnees au carre: var.cos2 = var.coord * var.coord.
# var$contrib: contient les contributions (en pourcentage), des variables, aux 
# composantes principales. La contribution d'une variable (var) e une composante 
# principale donnee: (var.cos2 * 100) / (total cos2 du composant).

# Coordonnees
head(var$coord)
# Correlation
head(var$cor)
# Cos2: qualite de representation
head(var$cos2)
# Contributions aux composantes principales
(var$contrib)


# visualisation des coordonnees:
fviz_pca_var(res.pca, col.var = "black", axes = c(1, 2))
fviz_pca_var(res.pca, col.var = "black", axes = c(2, 3))
fviz_pca_var(res.pca, col.var = "black", axes = c(1, 5))

# Visualisation qualite:
library("corrplot")
corrplot(var$cos2, is.corr=FALSE)

# Colorer en fonction du cos2: qualite de representation
fviz_pca_var(res.pca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE # evite le chevauchement de texte
)
fviz_pca_var(res.pca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, # evite le chevauchement de texte
             axes = c(1,3)
)


# visualisation de la contribution:
library("corrplot")
corrplot(var$contrib, is.corr=FALSE)    

# Contributions des variables e PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
# Contributions des variables e PC3
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)



#------  Graphique des individus ------

ind <- get_pca_ind(res.pca)
ind

# Coordonnees des individus
head(ind$coord)
# Qualite des individus
head(ind$cos2)
# Contributions des individus
head(ind$contrib)

# visualisation

#fviz_pca_ind (res.pca)
#fviz_pca_ind (res.pca, axes = c(1,3))
#fviz_pca_ind (res.pca, col.ind = "cos2",
#              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
#              repel = TRUE # evite le chevauchement de texte
#)
#fviz_pca_ind (res.pca, col.ind = "cos2",
#              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
#              repel = TRUE, # evite le chevauchement de texte
#axes = c(3,4)
#              )



# ----- BIPLOT -----

# pour visualiser les deux: variables et ind
#fviz_pca_biplot(res.pca, repel = TRUE,
#                col.var = "#2E9FDF", # Couleur des variables
#                col.ind = "#696969"  # Couleur des individues
#)
#fviz_pca_biplot(res.pca, repel = TRUE,
#                col.var = "#2E9FDF", # Couleur des variables
#                col.ind = "#696969",  # Couleur des individues
#axes = c(1,3)
#                )

# Extraire les 8 premières dimensions de l'ACP
principal_components <- res.pca$ind$coord[, 1:8]

# Ajouter ces dimensions à votre jeu de données original
data_with_pcaSPIN <- cbind(data_with_pca, principal_components)

# Renommer les colonnes des composantes principales
colnames(data_with_pcaSPIN)[(ncol(data_with_pca) + 1):(ncol(data_with_pca) + 8)] <- paste0("DimSPIN", 1:8)

# Afficher les premières lignes du nouveau jeu de données pour vérifier
head(data_with_pcaSPIN)

```

```{r test_dimension}
# Charger les bibliothèques nécessaires
library(ggplot2)
library(dplyr)
library(tidyr)

# Supposons que votre jeu de données s'appelle data_with_pcaSPIN
# data_with_pcaSPIN <- read.csv("path_to_your_data.csv")

# Lister les noms des colonnes du jeu de données
cols <- colnames(data_with_pcaSPIN)

# Liste des colonnes à exclure
excluded_cols <- c("DimGAD1", "DimGAD2", "DimGAD3", "DimGAD4", "DimSPIN1", "DimSPIN2", "DimSPIN3", "DimSPIN4", "DimSPIN5", "DimSPIN6", "DimSPIN7", "DimSPIN8")

# Boucle à travers chaque colonne et créer les graphiques
for (col in cols) {
  if (!col %in% excluded_cols) {
    # Calculer les moyennes de DimGAD1 et DimSPIN1 pour chaque valeur unique de la colonne actuelle
    summary_data <- data_with_pcaSPIN %>%
      group_by(!!sym(col)) %>%
      summarize(mean_DimGAD1 = mean(DimGAD1, na.rm = TRUE),
                mean_DimSPIN1 = mean(DimSPIN1, na.rm = TRUE))
    
    # Reshaper les données pour ggplot
    summary_data_long <- summary_data %>%
      pivot_longer(cols = starts_with("mean"), 
                   names_to = "Variable", 
                   values_to = "Mean")
    
    # Créer le graphique
    p <- ggplot(summary_data_long, aes_string(x = col, y = "Mean", fill = "Variable")) +
      geom_bar(stat = "identity", position = "dodge") +
      labs(title = paste("Mean of DimGAD1 and DimSPIN1 by", col),
           x = col, 
           y = "Mean") +
      theme_minimal()
    
    # Afficher le graphique
    print(p)
  }
}

```
```{r regression_lineaire}


# Charger les packages
library(ggplot2)
library(broom)

# Assurez-vous que le dataframe data_with_pcaSPIN est chargé
# data_with_pcaSPIN <- read.csv("path_to_your_data.csv") # Par exemple

# Créer le modèle de régression linéaire
model_GAD <- lm(DimGAD1 ~ GADE + Game + SWL1 + SWL2 + SWL3 + SWL4 + SWL5 + Platform + Hours + DimSPIN1 + Narcissism + Gender + Age + Work + Degree + Reference, data = data_with_pcaSPIN)

anova(model_GAD)

# Afficher un résumé du modèle
summary(model_GAD)

# Graphique des résidus
residuals <- residuals(model_GAD)
fitted <- fitted(model_GAD)

ggplot(data = data.frame(fitted = fitted, residuals = residuals), aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Graphique des résidus",
       x = "Valeurs prédites",
       y = "Résidus")

# Graphique des valeurs observées vs prédites
observed <- data_with_pcaSPIN$DimGAD1

ggplot(data = data.frame(observed = observed, fitted = fitted), aes(x = observed, y = fitted)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "blue") +
  labs(title = "Valeurs observées vs prédites",
       x = "Valeurs observées",
       y = "Valeurs prédites")

# Extraire les coefficients et leurs intervalles de confiance
tidy_model <- tidy(model_GAD, conf.int = TRUE)

# Graphique des coefficients
ggplot(tidy_model, aes(x = term, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(title = "Graphique des coefficients",
       x = "Variable",
       y = "Coefficient estimé")

# Créer le modèle de régression linéaire
model_SPIN <- lm(DimSPIN1 ~ GADE + Game + SWL1 + SWL2 + SWL3 + SWL4 + SWL5 + Platform + Hours + DimGAD1 + Narcissism + Gender + Age + Work + Degree + Reference, data = data_with_pcaSPIN)

anova(model_SPIN)

# Afficher un résumé du modèle
summary(model_SPIN)

# Graphique des résidus
residuals <- residuals(model_SPIN)
fitted <- fitted(model_SPIN)

ggplot(data = data.frame(fitted = fitted, residuals = residuals), aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Graphique des résidus",
       x = "Valeurs prédites",
       y = "Résidus")

# Graphique des valeurs observées vs prédites
observed <- data_with_pcaSPIN$DimGAD1

ggplot(data = data.frame(observed = observed, fitted = fitted), aes(x = observed, y = fitted)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "blue") +
  labs(title = "Valeurs observées vs prédites",
       x = "Valeurs observées",
       y = "Valeurs prédites")

# Extraire les coefficients et leurs intervalles de confiance
tidy_model <- tidy(model_SPIN, conf.int = TRUE)

# Graphique des coefficients
ggplot(tidy_model, aes(x = term, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(title = "Graphique des coefficients",
       x = "Variable",
       y = "Coefficient estimé")


```
###résultat
En ce qui concerne la régression de DimGAD1, les variables continues qui ont une signification positive sont SWL4, Hours, DimSPIN1 et Narcissism. Les variables continues qui ont une signification négative sont SWL2, SWL3 et SWL5. Pour ce qui est des variables catégoriques, celles qui ont une signification sont GADE, Game, Gender, Work et Reference.

Pour la régression de DimSPIN1, les variables continues qui ont une signification positive sont Hours et DimGAD1. Les variables continues qui ont une signification négative sont SWL3, SWL5, Narcissism et Age. Pour ce qui est des variables catégoriques, celles qui ont une signification sont GADE, Game, Platform, Gender, Work et Degree.

###Conclusion
En somme, j'ai réussi à trouver des dimensions représentatives avec mon ACP et atteindre mes trois objectifs. L'exploration de mes données a été faite tout au long de mon projet que ce soit pour l'analyse globale, l'analyse de mon ACP ainsi que ma régression linéaire. J'ai réussi à trouver des dimensions représentatives des tests GAD et SPIN avec mon ACP et les tester sur l'ensemble de mes variables. Ma régression linéaire quant à elle a su mettre en évidence les variables qui avaient une signification dans mes données sur le sondage en lien avec l'anxiété.
